import csv
from torchvision import datasets, transforms
from scipy.linalg import sqrtm
from PIL import Image
from laplace_transformation import *
from visualization import *
from classifier import *

class GeneratedImagesDataset(Dataset):
    def __init__(self, images_dir, indices, transform=None):
        """
        Custom dataset for loading generated images.
        """
        self.images_dir = images_dir
        self.indices = indices
        self.transform = transform

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        image_idx = self.indices[idx]
        image_path = os.path.join(self.images_dir, f'img_{image_idx}.png')
        image = Image.open(image_path).convert('L')  # Convert to grayscale
        if self.transform:
            image = self.transform(image)
        return image, 0  # Return a dummy label

def extract_features(model, dataloader):
    model.eval()
    model.to(device)
    features_list = []

    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            _, features = model(images)
            features_list.append(features.cpu())

    features = torch.cat(features_list, dim=0)
    return features

def compute_statistics(features):
    features = features.numpy()
    mu = np.mean(features, axis=0)
    sigma = np.cov(features, rowvar=False)
    return mu, sigma

def calculate_fid(mu1, sigma1, mu2, sigma2):
    # Calculate sum squared difference between means
    diff = mu1 - mu2
    diff_squared = np.sum(diff ** 2)

    # Compute square root of product of covariances
    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)
    # Numerical stability
    if np.iscomplexobj(covmean):
        covmean = covmean.real

    fid = diff_squared + np.trace(sigma1 + sigma2 - 2 * covmean)
    return fid




os.makedirs('./uncertainties', exist_ok=True)
os.makedirs('./uncertainties/FMNIST', exist_ok=True)
os.makedirs('./uncertainties/FMNIST/map_images_FMNIST', exist_ok=True)
os.makedirs('./uncertainties/FMNIST/uncertainties_FMNIST', exist_ok=True)
os.makedirs('./uncertainties/MNIST', exist_ok=True)
os.makedirs('./uncertainties/MNIST/map_images_MNIST', exist_ok=True)
os.makedirs('./uncertainties/MNIST/uncertainties_MNIST', exist_ok=True)
os.makedirs('./uncertainties_new', exist_ok=True)
os.makedirs('./uncertainties_new/FMNIST', exist_ok=True)
os.makedirs('./uncertainties_new/FMNIST/map_images_FMNIST', exist_ok=True)
os.makedirs('./uncertainties_new/FMNIST/uncertainties_FMNIST', exist_ok=True)
os.makedirs('./uncertainties_new/MNIST', exist_ok=True)
os.makedirs('./uncertainties_new/MNIST/map_images_MNIST', exist_ok=True)
os.makedirs('./uncertainties_new/MNIST/uncertainties_MNIST', exist_ok=True)


def save_map_image(img, idx, output_dir):
    """
    Saves image generated by pretrained model.
    """
    os.makedirs(output_dir, exist_ok=True)
    map_image = img.squeeze(0)
    img = map_image.detach().cpu().numpy()
    img = (img + 1) / 2.0
    img = (img * 255).astype('uint8')
    if img.shape[0] == 1:
        img = img.squeeze(0)
    img_pil = Image.fromarray(img)
    img_pil.save(f"{output_dir}/img_{idx}.png")


def save_uncertainties_to_csv(index, uncertainty, file_name):
    """
    Save a single row of image index and image uncertainty.
    """
    # Check if the file exists to avoid writing the header multiple times
    file_exists = os.path.isfile(file_name)

    with open(file_name, mode='a', newline='') as file:
        writer = csv.writer(file)

        # Write the header only if the file is being created
        if not file_exists:
            writer.writerow(["Image index", "Uncertainty"])

        # Write the data row for the current iteration
        writer.writerow([index, uncertainty])

    print(f"Results saved for image {index} to {file_name}")


def load_uncertainties_from_csv(file_name):
    """
    Loads saved uncertainties from a CSV file.
    """
    indexes, uncertainties = [], []

    with open(file_name, mode='r') as file:
        reader = csv.reader(file)
        next(reader)  # Skip the header
        for row in reader:
            index, uncertainty = int(row[0]), float(row[1])
            indexes.append(index)
            uncertainties.append(uncertainty)

    return indexes, uncertainties


def get_uncertainties_per_image(num_models, laplace_path, model_path, output_dir, uncertainties_dir, save_path):
    """
    Computes uncertainty for 10000 different images.
    """

    # Step 0: Load pretrained model and Laplace

    noise_dim = 100
    weights_MAP = r'../models/MAP_models/weights_MNIST'
    weights_laplace =  "../models/laplace_models/freezed_diag_classification_MNIST.bin"

    # checking the availability of cuda devices
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    # Loading or training of laplace model

    laplace = LaplaceTransformation(weights_MAP, noise_dim, device, conditional=False)
    laplace.load_map_model()
    laplace.load_laplace_model(weights_laplace, "classification", "all", "diag")
    model = laplace.laplace_model

    uncertainties = []
    images = []
    for i in range(10):

        # Step 1: Fix the latent variable and get random label
        noise = torch.randn(noise_dim, 1, 1, device=device).unsqueeze(0)
        image_map = laplace.map_model.generate_image(noise)
        images.append(image_map)
        save_map_image(image_map, i, output_dir)

        py, sampled_images = model(noise, pred_type="nn", link_approx="mc", n_samples=100)
        sampled_images = sampled_images.squeeze(1)

        # Step 4: Compute uncertainty as variance over the 100 models.
        variance_rgb, variance_grayscale, total_variance = plot_MAP_and_uncertainty(sampled_images, image_map, rgb=False)


        save_uncertainties_to_csv(i, total_variance, file_name=save_path)

        uncertainties.append(total_variance)

        print(f'Iteration {i + 1}: DONE')

    #images = torch.cat(images)
    return uncertainties, images

def get_uncertainty_fid_correlation(dataset, uncertainties_path, classifier_path, generated_images_path, num_bins):

    # Load uncertainties
    indexes, uncertainties = load_uncertainties_from_csv(file_name=uncertainties_path)

    # Sort uncertainties
    index_uncertainty_pairs = list(zip(indexes, uncertainties))
    sorted_pairs = sorted(index_uncertainty_pairs, key=lambda x: x[1])
    sorted_indexes, sorted_uncertainties = zip(*sorted_pairs)
    sorted_indexes = list(sorted_indexes)
    sorted_uncertainties = list(sorted_uncertainties)

    # Create bins
    total_images = len(sorted_indexes)
    bin_size = total_images // num_bins

    bins = []
    for i in range(num_bins):
        start_index = i * bin_size
        # For the last bin, include all remaining images
        if i != num_bins - 1:
            end_index = (i + 1) * bin_size
        else:
            end_index = total_images
        bin_indices = sorted_indexes[start_index:end_index]
        bins.append(bin_indices)

    # Transformations
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # Load original dataset
    if dataset == 'MNIST':
        original_dataset = datasets.MNIST(root='../datasets', train=True, transform=transform, download=True)
    elif dataset == 'Fashion-MNIST':
        original_dataset = datasets.FashionMNIST(root='../datasets', train=True, transform=transform, download=True)

    # Randomly select 2000 images from the original dataset
    # original_indices = random.sample(range(len(original_dataset)), bin_size)
    # original_subset = torch.utils.data.Subset(original_dataset, original_indices)
    original_loader = DataLoader(original_dataset, batch_size=64, shuffle=False)

    # Set the device to CPU
    device = torch.device("cpu")

    # Load classifier onto CPU
    model = CNNClassifier(num_classes=10).to(device)
    model.load_state_dict(torch.load(classifier_path, map_location=device))

    # Extract features for original images
    original_features = extract_features(model, original_loader)
    mu_orig, sigma_orig = compute_statistics(original_features)

    # Compute FID for each bin
    fid_scores = []
    for i, bin_indices in enumerate(bins):
        # Generated images in bin
        generated_dataset = GeneratedImagesDataset(images_dir=generated_images_path, indices=bin_indices,
                                             transform=transform)
        generated_loader = DataLoader(generated_dataset, batch_size=64, shuffle=False)

        # Extract features
        generated_features = extract_features(model, generated_loader)
        mu_gen, sigma_gen = compute_statistics(generated_features)

        # Compute FID
        fid = calculate_fid(mu_orig, sigma_orig, mu_gen, sigma_gen)
        fid_scores.append(fid)

        print(f'Bin {i + 1}, FID: {fid}')

    # Plot FID scores
    bins_labels = [f'Bin {i + 1}' for i in range(num_bins)]
    plt.figure(figsize=(10, 6))
    plt.bar(bins_labels, fid_scores, color='skyblue')
    plt.xlabel('Bins (Ordered by Increasing Uncertainty)')
    plt.ylabel('FID Score')
    plt.title('FID Scores Across Bins of Increasing Uncertainty')
    plt.show()



def main():
    uncertainties, images = get_uncertainties_per_image(num_models=100, laplace_path='laplace/la_cvae_MSE_full_batch_32_MNIST.bin',
                                     model_path='vae/saved_model_MNIST_cond/MNIST--e30-z128-Oct-19-18-27-PM.bin',
                                 output_dir='./uncertainties_new/MNIST/map_images_MNIST', uncertainties_dir='./uncertainties_new/MNIST/uncertainties_MNIST',
                                 save_path='./uncertainties_new/MNIST/uncertainties_MNIST/uncertainties.csv')
    get_uncertainty_fid_correlation(dataset='MNIST', uncertainties_path='./uncertainties_new/MNIST/uncertainties_MNIST/uncertainties.csv',
                                    classifier_path='../models/classifier_models/best_model_mnist.bin', generated_images_path='./uncertainties_new/MNIST/map_images_MNIST',
                                    num_bins=5)
    # get_uncertainty_fid_correlation_new(dataset='MNIST', uncertainties=uncertainties, images=images,
    #                                     classifier_path='./fid/checkpoints/MNIST/best_model_f_mnist.bin',
    #                                     num_bins=5)



if __name__ == '__main__':
     main()
